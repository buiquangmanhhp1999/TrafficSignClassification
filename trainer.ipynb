{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import TrafficSignDataset, Collator\n",
    "from model.repvgg import create_RepVGG_A0\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create Traffic Sign Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Create data for class Pedestrians: 100%|██████████████████████| 450/450 [00:00<00:00, 977946.53it/s]\n",
      "Create data for class Road work: 100%|█████████████████████| 2850/2850 [00:00<00:00, 1158310.70it/s]\n",
      "Create data for class Ahead only: 100%|████████████████████| 2280/2280 [00:00<00:00, 1221173.94it/s]\n",
      "Create data for class Children crossing: 100%|█████████████| 1020/1020 [00:00<00:00, 1132395.47it/s]\n",
      "Create data for class End of all speed and passing limits: 100%|█| 450/450 [00:00<00:00, 1122138.41i\n",
      "Create data for class Road narrows on the right: 100%|███████| 510/510 [00:00<00:00, 1097534.65it/s]\n",
      "Create data for class Double curve: 100%|████████████████████| 600/600 [00:00<00:00, 1081006.19it/s]\n",
      "Create data for class Speed limit (100km/h): 100%|█████████| 2730/2730 [00:00<00:00, 1155443.99it/s]\n",
      "Create data for class Keep right: 100%|████████████████████| 3930/3930 [00:00<00:00, 1180943.88it/s]\n",
      "Create data for class Wild animals crossing: 100%|█████████| 1470/1470 [00:00<00:00, 1161135.01it/s]\n",
      "Create data for class Speed limit (20km/h): 100%|████████████| 451/451 [00:00<00:00, 1234746.15it/s]\n",
      "Create data for class Speed limit (80km/h): 100%|██████████| 3510/3510 [00:00<00:00, 1398499.77it/s]\n",
      "Create data for class Stop: 100%|██████████████████████████| 1470/1470 [00:00<00:00, 1624243.12it/s]\n",
      "Create data for class Bicycles crossing: 100%|███████████████| 510/510 [00:00<00:00, 1685654.09it/s]\n",
      "Create data for class Right-of-way at the next intersection: 100%|█| 2490/2490 [00:00<00:00, 1813792\n",
      "Create data for class Beware of ice/snow: 100%|██████████████| 840/840 [00:00<00:00, 1924202.82it/s]\n",
      "Create data for class No passing for vechiles over 3.5 metric tons: 100%|█| 3810/3810 [00:00<00:00, \n",
      "Create data for class Slippery road: 100%|███████████████████| 960/960 [00:00<00:00, 1942369.44it/s]\n",
      "Create data for class End of speed limit (80km/h): 100%|█████| 780/780 [00:00<00:00, 1999729.29it/s]\n",
      "Create data for class Go straight or left: 100%|█████████████| 390/390 [00:00<00:00, 1860953.99it/s]\n",
      "Create data for class No entry: 100%|██████████████████████| 2100/2100 [00:00<00:00, 1840375.76it/s]\n",
      "Create data for class Dangerous curve to the right: 100%|████| 660/660 [00:00<00:00, 1851665.98it/s]\n",
      "Create data for class Speed limit (50km/h): 100%|██████████| 2610/2610 [00:00<00:00, 1911161.56it/s]\n",
      "Create data for class Speed limit (30km/h): 100%|██████████| 4920/4920 [00:00<00:00, 1887321.72it/s]\n",
      "Create data for class Turn left ahead: 100%|█████████████████| 780/780 [00:00<00:00, 1895456.04it/s]\n",
      "Create data for class End of no passing: 100%|███████████████| 450/450 [00:00<00:00, 1846807.05it/s]\n",
      "Create data for class Speed limit (120km/h): 100%|█████████| 2670/2670 [00:00<00:00, 1988774.94it/s]\n",
      "Create data for class Keep left: 100%|███████████████████████| 570/570 [00:00<00:00, 1914133.93it/s]\n",
      "Create data for class Dangerous curve to the left: 100%|█████| 390/390 [00:00<00:00, 1829729.93it/s]\n",
      "Create data for class Speed limit (70km/h): 100%|██████████| 3750/3750 [00:00<00:00, 1462585.08it/s]\n",
      "Create data for class Yield: 100%|█████████████████████████| 4080/4080 [00:00<00:00, 1870451.45it/s]\n",
      "Create data for class Traffic signals: 100%|███████████████| 1140/1140 [00:00<00:00, 1981560.94it/s]\n",
      "Create data for class No vechiles: 100%|███████████████████| 1170/1170 [00:00<00:00, 1993231.39it/s]\n",
      "Create data for class Roundabout mandatory: 100%|████████████| 660/660 [00:00<00:00, 1709845.98it/s]\n",
      "Create data for class Go straight or right: 100%|████████████| 720/720 [00:00<00:00, 1878046.57it/s]\n",
      "Create data for class General caution: 100%|███████████████| 2280/2280 [00:00<00:00, 1912602.62it/s]\n",
      "Create data for class Turn right ahead: 100%|██████████████| 1288/1288 [00:00<00:00, 1951684.81it/s]\n",
      "Create data for class Speed limit (60km/h): 100%|██████████| 2670/2670 [00:00<00:00, 1860264.40it/s]\n",
      "Create data for class Bumpy road: 100%|██████████████████████| 720/720 [00:00<00:00, 1805080.02it/s]\n",
      "Create data for class End of no passing by vechiles over 3.5 metric tons: 100%|█| 450/450 [00:00<00:\n",
      "Create data for class No passing: 100%|████████████████████| 2790/2790 [00:00<00:00, 1929449.00it/s]\n",
      "Create data for class Vechiles over 3.5 metric tons prohibited: 100%|█| 780/780 [00:00<00:00, 176269\n",
      "Create data for class Priority road: 100%|█████████████████| 3990/3990 [00:00<00:00, 1739271.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "The number of data: 73139. The number of classes: 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = TrafficSignDataset(image_dir='./Data/myData/', label_file='./Data/labels.csv', target_shape=(32, 32))\n",
    "nb_classes = len(np.unique(dataset.labels))\n",
    "print('------------------------------------------------------')\n",
    "print('The number of data: {}. The number of classes: {}'.format(len(dataset), nb_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Split train and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train and val dataloader\n",
    "split_ratio = 0.9\n",
    "n_train = int(len(dataset) * split_ratio)\n",
    "n_val = len(dataset) - n_train\n",
    "train_dataset, val_dataset = random_split(dataset, [n_train, n_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of train data:  65825\n",
      "The number of val data:  7314\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of train data: \", len(train_dataset))\n",
    "print(\"The number of val data: \", len(val_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "valid_every = 2000\n",
    "print_every = 500\n",
    "lr = 0.001\n",
    "num_iters = 60000\n",
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create dataloader for loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=Collator(), shuffle=True, num_workers=8, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, collate_fn=Collator(), shuffle=False, num_workers=8, pin_memory=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create RepVGG model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "repvgg_model = create_RepVGG_A0(num_classes=nb_classes)\n",
    "repvgg_model = repvgg_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Define a loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = AdamW(repvgg_model.parameters(), lr=lr, betas=(0.9, 0.98), eps=1e-09)\n",
    "scheduler = OneCycleLR(optimizer, max_lr=lr, total_steps=num_iters, pct_start=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_to_device(images, gts):\n",
    "    images = images.to(device, non_blocking=True)\n",
    "    gts = gts.to(device, non_blocking=True)\n",
    "    \n",
    "    return images, gts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_acc(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate():\n",
    "    repvgg_model.eval()\n",
    "    total_loss = []\n",
    "    total_acc = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            images, gts = batch\n",
    "            images, gts = batch_to_device(images, gts)\n",
    "            outputs = repvgg_model(images)\n",
    "            loss = criterion(outputs, gts)\n",
    "            acc = cal_acc(outputs, gts)\n",
    "            \n",
    "            total_loss.append(loss.item())\n",
    "            total_acc.append(acc)\n",
    "            \n",
    "            del outputs\n",
    "            del loss\n",
    "            \n",
    "    val_loss = np.mean(total_loss)\n",
    "    val_acc = np.mean(total_acc)\n",
    "    repvgg_model.train()\n",
    "    \n",
    "    return val_loss, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(batch):\n",
    "    # get the inputs\n",
    "    images, gts = batch\n",
    "    images, gts = batch_to_device(images, gts)\n",
    "\n",
    "    # zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # forward + backward + optimize + scheduler\n",
    "    outputs = repvgg_model(images)\n",
    "    loss = criterion(outputs, gts)\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(repvgg_model.parameters(), 1) \n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    loss_item = loss.item()\n",
    "    \n",
    "    return loss_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 000500, train_loss: 2.7534\n",
      "step: 001000, train_loss: 0.9924\n",
      "step: 001500, train_loss: 0.3827\n",
      "step: 002000, train_loss: 0.2445\n",
      "==============================================================================\n",
      "val_loss: 0.2385, val_acc: 0.9328\n",
      "==============================================================================\n",
      "step: 002500, train_loss: 0.1895\n",
      "step: 003000, train_loss: 0.1556\n",
      "step: 003500, train_loss: 0.1186\n",
      "step: 004000, train_loss: 0.1007\n",
      "==============================================================================\n",
      "val_loss: 0.0902, val_acc: 0.9762\n",
      "==============================================================================\n",
      "step: 004500, train_loss: 0.0748\n",
      "step: 005000, train_loss: 0.0559\n",
      "step: 005500, train_loss: 0.0512\n",
      "step: 006000, train_loss: 0.0370\n",
      "==============================================================================\n",
      "val_loss: 0.0529, val_acc: 0.9841\n",
      "==============================================================================\n",
      "step: 006500, train_loss: 0.0295\n",
      "step: 007000, train_loss: 0.0248\n",
      "step: 007500, train_loss: 0.0251\n",
      "step: 008000, train_loss: 0.0262\n",
      "==============================================================================\n",
      "val_loss: 0.0269, val_acc: 0.9930\n",
      "==============================================================================\n",
      "step: 008500, train_loss: 0.0157\n",
      "step: 009000, train_loss: 0.0180\n",
      "step: 009500, train_loss: 0.0137\n",
      "step: 010000, train_loss: 0.0136\n",
      "==============================================================================\n",
      "val_loss: 0.0221, val_acc: 0.9955\n",
      "==============================================================================\n",
      "step: 010500, train_loss: 0.0120\n",
      "step: 011000, train_loss: 0.0104\n",
      "step: 011500, train_loss: 0.0094\n",
      "step: 012000, train_loss: 0.0107\n",
      "==============================================================================\n",
      "val_loss: 0.1320, val_acc: 0.9949\n",
      "==============================================================================\n",
      "step: 012500, train_loss: 0.0094\n",
      "step: 013000, train_loss: 0.0103\n",
      "step: 013500, train_loss: 0.0074\n",
      "step: 014000, train_loss: 0.0090\n",
      "==============================================================================\n",
      "val_loss: 0.0166, val_acc: 0.9963\n",
      "==============================================================================\n",
      "step: 014500, train_loss: 0.0095\n",
      "step: 015000, train_loss: 0.0072\n",
      "step: 015500, train_loss: 0.0095\n",
      "step: 016000, train_loss: 0.0092\n",
      "==============================================================================\n",
      "val_loss: 0.0149, val_acc: 0.9967\n",
      "==============================================================================\n",
      "step: 016500, train_loss: 0.0063\n",
      "step: 017000, train_loss: 0.0082\n",
      "step: 017500, train_loss: 0.0069\n",
      "step: 018000, train_loss: 0.0083\n",
      "==============================================================================\n",
      "val_loss: 0.0209, val_acc: 0.9971\n",
      "==============================================================================\n",
      "step: 018500, train_loss: 0.0063\n",
      "step: 019000, train_loss: 0.0042\n",
      "step: 019500, train_loss: 0.0085\n",
      "step: 020000, train_loss: 0.0076\n",
      "==============================================================================\n",
      "val_loss: 32.9906, val_acc: 0.9958\n",
      "==============================================================================\n",
      "step: 020500, train_loss: 0.0067\n",
      "step: 021000, train_loss: 0.0047\n",
      "step: 021500, train_loss: 0.0037\n",
      "step: 022000, train_loss: 0.0042\n",
      "==============================================================================\n",
      "val_loss: 0.0135, val_acc: 0.9974\n",
      "==============================================================================\n",
      "step: 022500, train_loss: 0.0030\n",
      "step: 023000, train_loss: 0.0043\n",
      "step: 023500, train_loss: 0.0049\n",
      "step: 024000, train_loss: 0.0121\n",
      "==============================================================================\n",
      "val_loss: 0.0262, val_acc: 0.9975\n",
      "==============================================================================\n",
      "step: 024500, train_loss: 0.0242\n",
      "step: 025000, train_loss: 0.0027\n",
      "step: 025500, train_loss: 0.0032\n",
      "step: 026000, train_loss: 0.0029\n",
      "==============================================================================\n",
      "val_loss: 34.2389, val_acc: 0.9944\n",
      "==============================================================================\n",
      "step: 026500, train_loss: 0.0027\n",
      "step: 027000, train_loss: 0.0121\n",
      "step: 027500, train_loss: 0.0144\n",
      "step: 028000, train_loss: 0.0024\n",
      "==============================================================================\n",
      "val_loss: 268.8508, val_acc: 0.9952\n",
      "==============================================================================\n",
      "step: 028500, train_loss: 0.0016\n",
      "step: 029000, train_loss: 0.0014\n",
      "step: 029500, train_loss: 0.0016\n",
      "step: 030000, train_loss: 0.0025\n",
      "==============================================================================\n",
      "val_loss: 0.0171, val_acc: 0.9977\n",
      "==============================================================================\n",
      "step: 030500, train_loss: 0.0017\n",
      "step: 031000, train_loss: 0.0019\n",
      "step: 031500, train_loss: 0.0012\n",
      "step: 032000, train_loss: 0.0132\n",
      "==============================================================================\n",
      "val_loss: 29.0463, val_acc: 0.9942\n",
      "==============================================================================\n",
      "step: 032500, train_loss: 0.0013\n",
      "step: 033000, train_loss: 0.0047\n",
      "step: 033500, train_loss: 0.0015\n",
      "step: 034000, train_loss: 0.0009\n",
      "==============================================================================\n",
      "val_loss: 0.0107, val_acc: 0.9984\n",
      "==============================================================================\n",
      "step: 034500, train_loss: 0.0009\n",
      "step: 035000, train_loss: 0.0013\n",
      "step: 035500, train_loss: 0.0029\n",
      "step: 036000, train_loss: 0.0006\n",
      "==============================================================================\n",
      "val_loss: 0.0169, val_acc: 0.9984\n",
      "==============================================================================\n",
      "step: 036500, train_loss: 0.0004\n",
      "step: 037000, train_loss: 0.0005\n",
      "step: 037500, train_loss: 0.0006\n",
      "step: 038000, train_loss: 0.0007\n",
      "==============================================================================\n",
      "val_loss: 3176.5771, val_acc: 0.9934\n",
      "==============================================================================\n",
      "step: 038500, train_loss: 0.0005\n",
      "step: 039000, train_loss: 0.0002\n",
      "step: 039500, train_loss: 0.0005\n",
      "step: 040000, train_loss: 0.0002\n",
      "==============================================================================\n",
      "val_loss: 153.6445, val_acc: 0.9911\n",
      "==============================================================================\n",
      "step: 040500, train_loss: 0.0000\n",
      "step: 041000, train_loss: 0.0001\n",
      "step: 041500, train_loss: 0.0000\n",
      "step: 042000, train_loss: 0.0004\n",
      "==============================================================================\n",
      "val_loss: 26.4879, val_acc: 0.9942\n",
      "==============================================================================\n",
      "step: 042500, train_loss: 0.0000\n",
      "step: 043000, train_loss: 0.0086\n",
      "step: 043500, train_loss: 0.0000\n",
      "step: 044000, train_loss: 0.0000\n",
      "==============================================================================\n",
      "val_loss: 47.0364, val_acc: 0.9962\n",
      "==============================================================================\n",
      "step: 044500, train_loss: 0.0086\n",
      "step: 045000, train_loss: 0.0000\n",
      "step: 045500, train_loss: 0.0036\n",
      "step: 046000, train_loss: 0.0000\n",
      "==============================================================================\n",
      "val_loss: 24.5237, val_acc: 0.9956\n",
      "==============================================================================\n",
      "step: 046500, train_loss: 0.0000\n",
      "step: 047000, train_loss: 0.0000\n",
      "step: 047500, train_loss: 0.0000\n",
      "step: 048000, train_loss: 0.0050\n",
      "==============================================================================\n",
      "val_loss: 35.7156, val_acc: 0.9959\n",
      "==============================================================================\n",
      "step: 048500, train_loss: 0.0000\n",
      "step: 049000, train_loss: 0.0000\n",
      "step: 049500, train_loss: 0.0000\n",
      "step: 050000, train_loss: 0.0000\n",
      "==============================================================================\n",
      "val_loss: 32.2654, val_acc: 0.9958\n",
      "==============================================================================\n",
      "step: 050500, train_loss: 0.0000\n",
      "step: 051000, train_loss: 0.0000\n",
      "step: 051500, train_loss: 0.0074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 052000, train_loss: 0.0000\n",
      "==============================================================================\n",
      "val_loss: 37.5417, val_acc: 0.9963\n",
      "==============================================================================\n",
      "step: 052500, train_loss: 0.0000\n",
      "step: 053000, train_loss: 0.0000\n",
      "step: 053500, train_loss: 0.0001\n",
      "step: 054000, train_loss: 0.0000\n",
      "==============================================================================\n",
      "val_loss: 28.9426, val_acc: 0.9962\n",
      "==============================================================================\n",
      "step: 054500, train_loss: 0.0000\n",
      "step: 055000, train_loss: 0.0000\n",
      "step: 055500, train_loss: 0.0000\n",
      "step: 056000, train_loss: 0.0000\n",
      "==============================================================================\n",
      "val_loss: 37.2928, val_acc: 0.9962\n",
      "==============================================================================\n",
      "step: 056500, train_loss: 0.0000\n",
      "step: 057000, train_loss: 0.0000\n",
      "step: 057500, train_loss: 0.0000\n",
      "step: 058000, train_loss: 0.0000\n",
      "==============================================================================\n",
      "val_loss: 641.1455, val_acc: 0.9952\n",
      "==============================================================================\n",
      "step: 058500, train_loss: 0.0000\n",
      "step: 059000, train_loss: 0.0000\n",
      "step: 059500, train_loss: 0.0000\n",
      "step: 060000, train_loss: 0.0000\n",
      "==============================================================================\n",
      "val_loss: 45.0168, val_acc: 0.9959\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "total_loss = 0\n",
    "best_acc = 0\n",
    "global_step = 0\n",
    "weight_path = 'repvgg.pth'\n",
    "\n",
    "data_iter = iter(train_loader)\n",
    "for i in range(num_iters):\n",
    "    repvgg_model.train()\n",
    "    \n",
    "    try:\n",
    "        batch = next(data_iter)\n",
    "    except StopIteration:\n",
    "        data_iter = iter(train_loader)\n",
    "        batch = next(data_iter)\n",
    "        \n",
    "    global_step += 1\n",
    "    loss = train_step(batch)\n",
    "    total_loss += loss\n",
    "\n",
    "    if global_step % print_every == 0:\n",
    "        print('step: {:06d}, train_loss: {:.4f}'.format(global_step, total_loss / print_every))\n",
    "        total_loss = 0\n",
    "        \n",
    "\n",
    "    if global_step % valid_every == 0:\n",
    "        # validate \n",
    "        val_loss, val_acc = validate()\n",
    "        \n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(repvgg_model.state_dict(), weight_path)\n",
    "            \n",
    "        print(\"==============================================================================\")\n",
    "        print(\"val_loss: {:.4f}, val_acc: {:.4f}\".format(val_loss, val_acc))\n",
    "        print(\"==============================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VietnameseRCNN",
   "language": "python",
   "name": "vietnamesercnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
