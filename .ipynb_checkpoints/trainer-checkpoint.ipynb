{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import TrafficSignDataset, Collator\n",
    "from model.repvgg import create_RepVGG_A0\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create Traffic Sign Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Create data for class Road narrows on the right: 100%|███████| 510/510 [00:00<00:00, 1222340.02it/s]\n",
      "Create data for class Speed limit (30km/h): 100%|██████████| 4920/4920 [00:00<00:00, 1110476.01it/s]\n",
      "Create data for class Beware of ice/snow: 100%|██████████████| 840/840 [00:00<00:00, 1454671.91it/s]\n",
      "Create data for class Turn right ahead: 100%|██████████████| 1288/1288 [00:00<00:00, 1437919.50it/s]\n",
      "Create data for class Wild animals crossing: 100%|█████████| 1470/1470 [00:00<00:00, 1377178.22it/s]\n",
      "Create data for class Double curve: 100%|████████████████████| 600/600 [00:00<00:00, 1392685.33it/s]\n",
      "Create data for class Bumpy road: 100%|██████████████████████| 720/720 [00:00<00:00, 1182882.44it/s]\n",
      "Create data for class Dangerous curve to the left: 100%|█████| 390/390 [00:00<00:00, 1232689.19it/s]\n",
      "Create data for class Speed limit (70km/h): 100%|██████████| 3750/3750 [00:00<00:00, 1261318.36it/s]\n",
      "Create data for class No entry: 100%|██████████████████████| 2100/2100 [00:00<00:00, 1403224.22it/s]\n",
      "Create data for class Turn left ahead: 100%|█████████████████| 780/780 [00:00<00:00, 1380986.54it/s]\n",
      "Create data for class End of all speed and passing limits: 100%|█| 450/450 [00:00<00:00, 405464.40it\n",
      "Create data for class End of no passing: 100%|████████████████| 450/450 [00:00<00:00, 673363.11it/s]\n",
      "Create data for class Ahead only: 100%|████████████████████| 2280/2280 [00:00<00:00, 1183394.77it/s]\n",
      "Create data for class Vechiles over 3.5 metric tons prohibited: 100%|█| 780/780 [00:00<00:00, 511740\n",
      "Create data for class Traffic signals: 100%|████████████████| 1140/1140 [00:00<00:00, 306998.82it/s]\n",
      "Create data for class Children crossing: 100%|██████████████| 1020/1020 [00:00<00:00, 723033.65it/s]\n",
      "Create data for class Speed limit (120km/h): 100%|██████████| 2670/2670 [00:00<00:00, 948487.48it/s]\n",
      "Create data for class Speed limit (20km/h): 100%|█████████████| 451/451 [00:00<00:00, 686368.33it/s]\n",
      "Create data for class Roundabout mandatory: 100%|█████████████| 660/660 [00:00<00:00, 460375.96it/s]\n",
      "Create data for class Stop: 100%|███████████████████████████| 1470/1470 [00:00<00:00, 715685.07it/s]\n",
      "Create data for class No passing for vechiles over 3.5 metric tons: 100%|█| 3810/3810 [00:00<00:00, \n",
      "Create data for class Speed limit (80km/h): 100%|███████████| 3510/3510 [00:00<00:00, 724900.64it/s]\n",
      "Create data for class Priority road: 100%|██████████████████| 3990/3990 [00:00<00:00, 626109.21it/s]\n",
      "Create data for class Keep left: 100%|████████████████████████| 570/570 [00:00<00:00, 703990.95it/s]\n",
      "Create data for class Go straight or left: 100%|██████████████| 390/390 [00:00<00:00, 504714.15it/s]\n",
      "Create data for class Road work: 100%|██████████████████████| 2850/2850 [00:00<00:00, 369879.52it/s]\n",
      "Create data for class No vechiles: 100%|████████████████████| 1170/1170 [00:00<00:00, 468123.22it/s]\n",
      "Create data for class Speed limit (60km/h): 100%|███████████| 2670/2670 [00:00<00:00, 534497.50it/s]\n",
      "Create data for class Speed limit (100km/h): 100%|██████████| 2730/2730 [00:00<00:00, 893101.16it/s]\n",
      "Create data for class Speed limit (50km/h): 100%|███████████| 2610/2610 [00:00<00:00, 710760.51it/s]\n",
      "Create data for class General caution: 100%|███████████████| 2280/2280 [00:00<00:00, 1224771.15it/s]\n",
      "Create data for class Slippery road: 100%|████████████████████| 960/960 [00:00<00:00, 766374.54it/s]\n",
      "Create data for class End of speed limit (80km/h): 100%|██████| 780/780 [00:00<00:00, 534306.24it/s]\n",
      "Create data for class Dangerous curve to the right: 100%|█████| 660/660 [00:00<00:00, 569245.45it/s]\n",
      "Create data for class End of no passing by vechiles over 3.5 metric tons: 100%|█| 450/450 [00:00<00:\n",
      "Create data for class Go straight or right: 100%|█████████████| 720/720 [00:00<00:00, 516928.94it/s]\n",
      "Create data for class Bicycles crossing: 100%|████████████████| 510/510 [00:00<00:00, 438069.84it/s]\n",
      "Create data for class Keep right: 100%|█████████████████████| 3930/3930 [00:00<00:00, 489752.94it/s]\n",
      "Create data for class No passing: 100%|█████████████████████| 2790/2790 [00:00<00:00, 438264.79it/s]\n",
      "Create data for class Yield: 100%|██████████████████████████| 4080/4080 [00:00<00:00, 525624.61it/s]\n",
      "Create data for class Right-of-way at the next intersection: 100%|█| 2490/2490 [00:00<00:00, 857526.\n",
      "Create data for class Pedestrians: 100%|█████████████████████| 450/450 [00:00<00:00, 1053257.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "The number of data: 73139. The number of classes: 43\n"
     ]
    }
   ],
   "source": [
    "dataset = TrafficSignDataset(image_dir='./Data/myData/', label_file='./Data/labels.csv', target_shape=(32, 32))\n",
    "nb_classes = len(np.unique(dataset.labels))\n",
    "print('------------------------------------------------------')\n",
    "print('The number of data: {}. The number of classes: {}'.format(len(dataset), nb_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Split train and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train and val dataloader\n",
    "split_ratio = 0.9\n",
    "n_train = int(len(dataset) * split_ratio)\n",
    "n_val = len(dataset) - n_train\n",
    "train_dataset, val_dataset = random_split(dataset, [n_train, n_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of train data:  65825\n",
      "The number of val data:  7314\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of train data: \", len(train_dataset))\n",
    "print(\"The number of val data: \", len(val_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "valid_every = 500\n",
    "print_every = 100\n",
    "lr = 0.001\n",
    "num_iters = 30000\n",
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create dataloader for loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=Collator(), shuffle=True, num_workers=8, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, collate_fn=Collator(), shuffle=False, num_workers=8, pin_memory=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create RepVGG model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "repvgg_model = create_RepVGG_A0(num_classes=nb_classes)\n",
    "repvgg_model = repvgg_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Define a loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = AdamW(repvgg_model.parameters(), lr=lr, betas=(0.9, 0.98), eps=1e-09)\n",
    "scheduler = OneCycleLR(optimizer, max_lr=lr, total_steps=num_iters, pct_start=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_to_device(images, gts):\n",
    "    images = images.to(device, non_blocking=True)\n",
    "    gts = gts.to(device, non_blocking=True)\n",
    "    \n",
    "    return images, gts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_acc(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate():\n",
    "    repvgg_model.eval()\n",
    "    total_loss = []\n",
    "    total_acc = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            images, gts = batch\n",
    "            images, gts = batch_to_device(images, gts)\n",
    "            outputs = repvgg_model(images)\n",
    "            loss = criterion(outputs, gts)\n",
    "            acc = cal_acc(outputs, gts)\n",
    "            \n",
    "            total_loss.append(loss.item())\n",
    "            total_acc.append(acc)\n",
    "            \n",
    "            del outputs\n",
    "            del loss\n",
    "            \n",
    "    val_loss = np.mean(total_loss)\n",
    "    val_acc = np.mean(total_acc)\n",
    "    repvgg_model.train()\n",
    "    \n",
    "    return val_loss, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(batch):\n",
    "    # get the inputs\n",
    "    images, gts = batch\n",
    "    images, gts = batch_to_device(images, gts)\n",
    "\n",
    "    # zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # forward + backward + optimize + scheduler\n",
    "    outputs = repvgg_model(images)\n",
    "    loss = criterion(outputs, gts)\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(repvgg_model.parameters(), 1) \n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    loss_item = loss.item()\n",
    "    \n",
    "    return loss_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss = 0\n",
    "best_acc = 0\n",
    "global_step = 0\n",
    "weight_path = 'repvgg.pth'\n",
    "\n",
    "data_iter = iter(train_loader)\n",
    "for i in range(num_iters):\n",
    "    repvgg_model.train()\n",
    "    \n",
    "    try:\n",
    "        batch = next(data_iter)\n",
    "    except StopIteration:\n",
    "        data_iter = iter(self.train_gen)\n",
    "        batch = next(data_iter)\n",
    "        \n",
    "    global_step += 1\n",
    "    loss = train_step(batch)\n",
    "    total_loss += loss\n",
    "\n",
    "    if global_step % print_every == 0:\n",
    "        print('step: {:06d}, train_loss: {:.4f}'.format(global_step, total_loss / print_every))\n",
    "        total_loss = 0\n",
    "        \n",
    "\n",
    "    if global_step % valid_every == 0:\n",
    "        # validate \n",
    "        val_loss, val_acc = validate()\n",
    "        \n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(repvgg_model.state_dict(), weight_path)\n",
    "            \n",
    "        print(\"==============================================================================\")\n",
    "        print(\"val_loss: {:.4f}, val_acc: {:.4f}\".format(val_loss, val_acc))\n",
    "        print(\"==============================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "manhbq",
   "language": "python",
   "name": "manhbq"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
